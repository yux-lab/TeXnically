gpu_devices: 0 #[0,1,2,3,4,5,6,7]
backbone_layers:
- 2
- 3
- 7
betas:
- 0.9
- 0.999
batchsize: 1
bos_token: 1
channels: 1
data: dataset/data/demo.pkl
debug: false
decoder_args:
  attn_on_attn: true
  cross_attend: true
  ff_glu: true
  rel_pos_bias: false
  use_scalenorm: false
dim: 256
encoder_depth: 4
eos_token: 2
epochs: 1
gamma: 0.9995
heads: 8
id: null
load_chkpt: null
lr: 0.001
lr_step: 30
max_height: 192
max_seq_len: 512
max_width: 896
micro_batchsize: -1
min_height: 32
min_width: 32
model_path: checkpoints
name: train_small
num_layers: 4
num_tokens: 8000
optimizer: AdamW
output_path: outputs
pad: false
pad_token: 0
patch_size: 16
sample_freq: 3000
save_freq: 5
scheduler: StepLR
seed: 42
encoder_structure: hybrid
temperature: 0.2
test_samples: 20
testbatchsize: 20
tokenizer: model/dataset/tokenizer.json
valbatches: 600
valdata: dataset/data/demo.pkl